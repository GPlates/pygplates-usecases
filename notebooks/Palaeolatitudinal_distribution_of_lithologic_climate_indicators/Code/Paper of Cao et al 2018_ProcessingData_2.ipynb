{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Materials associated with the paper: \n",
    "\n",
    "Cao, W., Williams, S., Flament, N., Zahirovic, S., Scotese, C., and MÃ¼ller, R. D., 2018. Paleolatitudinal distribution of lithologic indicators of climate in a paleogeographic framework. Geological Magazine, 1-24. doi:10.1017/S0016756818000110.\n",
    "\n",
    "### This Jupyter notebook is used to (1) reconstruct lithologic data; (2) remove sampling bias; (3) save results using different binning size: 10, 5 and 2 degree\n",
    "\n",
    "The code in this notebook is written in Python 2.7. It utilizes standard scientific Python modules as well as modules from the open source pygplates which provides a Python API to the open source GPlates software (https://www.gplates.org/). Here, the source code has been modified to Python 3.7 by Behnam Sadeghi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygplates\n",
    "import os\n",
    "os.environ['PROJ_LIB'] = r'C:\\ProgramData\\Anaconda3\\pkgs\\proj4-5.1.0-hfa6e2cd_1\\Library\\share'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matthews2016 modified model\n",
    "point_feature_filename = '../Data/Lithologic_Data/Matthews2016_CEG_410.shp'\n",
    "input_feature_collection = pygplates.FeatureCollection(point_feature_filename)\n",
    "\n",
    "#Rotation:Global_EB_410-0Ma_GK07_Matthews_etal_PMAG_fixed_crossovers.rot\n",
    "input_rotation_filename_Matthews2016PMAG_fixed = ['../Data/Tectonic_model/Global_EB_410-0Ma_GK07_Matthews_etal.rot']\n",
    "rotation_model = pygplates.RotationModel(input_rotation_filename_Matthews2016PMAG_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paleolithology(point_features,rotation_model):\n",
    "    pX = []\n",
    "    pY = []\n",
    "    pAge = []\n",
    "    for point in point_features:\n",
    "        lithcode = point.get_shapefile_attribute('LithCode')\n",
    "        if lithcode == 'C' and point.get_reconstruction_plate_id()!=0:\n",
    "        #if lithcode == 'E' and point.get_reconstruction_plate_id()!=0:\n",
    "        #if lithcode== 'T' or lithcode=='D' or lithcode=='G' and point.get_reconstruction_plate_id()!=0:\n",
    "            BirthTime = np.median(point.get_valid_time())\n",
    "            if BirthTime<410:\n",
    "                pAge.append(BirthTime)\n",
    "                point_rotation = rotation_model.get_rotation(BirthTime, point.get_reconstruction_plate_id(), anchor_plate_id=0) #obtain rotating rules\n",
    "                reconstructed_point = point_rotation * point.get_geometry() # carry out reconstruction\n",
    "                pX.append(reconstructed_point.to_lat_lon()[1])\n",
    "                pY.append(reconstructed_point.to_lat_lon()[0])            \n",
    "    return (pX,pY,pAge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406.0\n",
      "390.5\n",
      "385.5\n",
      "371.0\n",
      "345.0\n",
      "327.0\n",
      "315.0\n",
      "303.0\n",
      "294.5\n",
      "271.0\n",
      "249.5\n",
      "242.0\n",
      "219.0\n",
      "182.5\n",
      "154.5\n",
      "129.0\n",
      "101.4\n",
      "77.9\n",
      "61.0\n",
      "51.9\n",
      "40.849999999999994\n",
      "28.45\n",
      "14.15\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "age_range_list = [(419,393),   # Early Devonian\n",
    "           (393,388),   # Middle Devonian (Eifelian)\n",
    "           (388,383),   # Middle Devonian (Givetian)\n",
    "           (383,359),   # Late Devonian\n",
    "           (359,331),   # Early Carboniferous (Tournaisian-Visean)\n",
    "           (331,323),   # Early Carboniferous (Serpukhovian)\n",
    "           (323,307),   # Late Carboniferous (Bashkirian-Moscovian)\n",
    "           (307,299),   # Late Carboniferous (Kasimovian-Gzhelian)\n",
    "           (299,290),   # Early Permian (Asselian-Sakmarian)\n",
    "           (290,252),   # Middle-Late Permian (Artinskian-Lopingian)\n",
    "           (252,247),   # Early Triassic\n",
    "           (247,237),   # Middle Triassic\n",
    "           (237,201),   # Late Triassic\n",
    "           (201,164),   # Early and Middle Jurassic\n",
    "           (164,145),   # Late Jurassic\n",
    "           (145,113),   # Early Cretaceous (Berriasian-Aptian)\n",
    "           (113,89.8),   # Late Cretaceous (Albian-Turonian)\n",
    "           (89.8,66.0),   # Late Cretaceous (Coniacian-Maastrichtian)\n",
    "           (66.0,56.0),   # Paleocene\n",
    "           (56.0,47.8),  # Early Eocene (Ypresian?)\n",
    "           (47.8,33.9),  # Middle and Late Eocene\n",
    "           (33.9,23.0),  # Oligocene\n",
    "           (23.0,5.3),    # Miocene\n",
    "           (0.01,-0.01)] # present-day\n",
    "#print age_range_list[5:]\n",
    "\n",
    "i = 0\n",
    "for i in np.arange(0,24,1):\n",
    "    Age = np.mean(age_range_list[i])\n",
    "    print (Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "11\n",
      "26\n",
      "189\n",
      "99\n",
      "291\n",
      "268\n",
      "298\n",
      "334\n",
      "19\n",
      "21\n",
      "228\n",
      "478\n",
      "86\n",
      "244\n",
      "162\n",
      "160\n",
      "116\n",
      "168\n",
      "233\n",
      "180\n",
      "384\n",
      "1352\n"
     ]
    }
   ],
   "source": [
    "# reconstruct all data and get their x, y coordinates and ages\n",
    "pX,pY,pAge = get_paleolithology(input_feature_collection,rotation_model)\n",
    "#print len(pX)\n",
    "#print pAge\n",
    "\n",
    "for j in np.arange(0,24,1):\n",
    "    n = 0\n",
    "    for i in np.arange(0,len(pAge),1):\n",
    "        if np.array(pAge[i]) == np.mean(age_range_list[j]):\n",
    "            n = n+1\n",
    "            #print (np.array(pAge[i]))\n",
    "            #print (np.mean(age_range_list[j]))\n",
    "    print (n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning size: 5 degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# remove the sampling bias\n",
    "\n",
    "result_original = []\n",
    "result_SamplingBiasRemoved = []\n",
    "result_flipped = []\n",
    "result_doubled = []\n",
    "\n",
    "for i in np.arange(0,24,1):\n",
    "    \n",
    "    result = []\n",
    "    result_0 = []\n",
    "    result_1 = []\n",
    "    result_2 = []\n",
    "    result_3 = []\n",
    "    \n",
    "    index = np.where(np.array(pAge) == np.mean(age_range_list[i]))\n",
    "    #print np.mean(age_range_list[i]),np.array(pAge)[index]\n",
    "    \n",
    "    xedges = np.arange(-180, 181, 5) #180, longtitude\n",
    "    yedges = np.arange(-90, 91, 5) #90, latitude, specify the bin size\n",
    "    data_hist = np.histogram2d(np.array(pX)[index],np.array(pY)[index], bins=(xedges, yedges))\n",
    "    result_0 = np.nansum(data_hist[0], axis=0)\n",
    "    result_original.append(result_0)\n",
    "    #print type(result_original)\n",
    "    \n",
    "    # save the original data\n",
    "    #df = pd.DataFrame(data_hist[0].T)\n",
    "    #writer = pd.ExcelWriter('OriginalData_Glacial_%sMa.xlsx' % np.mean(age_range_list[i]), engine='xlsxwriter') # Evaporite\n",
    "    #df.to_excel(writer, sheet_name='Sheet1')\n",
    "    #writer.save()\n",
    "    \n",
    "    # remove the sampling bias\n",
    "    result_1 = np.nansum(data_hist[0]/data_hist[0], axis=0)\n",
    "    #print result_1\n",
    "    result_SamplingBiasRemoved.append(result_1)\n",
    "    \n",
    "    #plt.pcolor(xedges,yedges,data_hist[0].T) #T means reverse the x, y axis\n",
    "    \n",
    "    # flip the data\n",
    "    #result_2 = np.flipud(result_1[:18])+result_1[18:]\n",
    "    #result_flipped.append(result_2) # add data on south hemisphere to north hemishpere\n",
    "    #print result_flipped\n",
    "    \n",
    "    # double the data\n",
    "    #result_3 = list(np.flipud(result_2)) + list(result_2) \n",
    "    #result_doubled.append(np.array(result_3)) # add data on south hemisphere to north hemishpere\n",
    "    #print result_doubled\n",
    "\n",
    "# save data for all time steps into a table\n",
    "df = pd.DataFrame(result_original)\n",
    "writer = pd.ExcelWriter('Output/ProcessingData_2/Coals_Matthews2016_Origianl_410-0Ma_BinningSize5.xlsx' % np.mean(age_range_list[i]), engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()\n",
    "\n",
    "# save sampling bias-corrected data for all time steps into a table\n",
    "df = pd.DataFrame(result_SamplingBiasRemoved)\n",
    "writer = pd.ExcelWriter('Output/ProcessingData_2/Coals_Matthews2016_SamplingBiasCorrected_410-0Ma_BinningSize5.xlsx' % np.mean(age_range_list[i]), engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()\n",
    "\n",
    "# save flipped data for all time steps into a table\n",
    "#df = pd.DataFrame(result_flipped)\n",
    "#writer = pd.ExcelWriter('Glacial_Golonka_Flipped_410-0Ma.xlsx' % np.mean(age_range_list[i]), engine='xlsxwriter')\n",
    "#df.to_excel(writer, sheet_name='Sheet1')\n",
    "#writer.save()\n",
    "\n",
    "# save flipped data for all time steps into a table\n",
    "#df = pd.DataFrame(result_doubled)\n",
    "#writer = pd.ExcelWriter('Glacial_Golonka_Doubled_410-0Ma.xlsx' % np.mean(age_range_list[i]), engine='xlsxwriter')\n",
    "#df.to_excel(writer, sheet_name='Sheet1')\n",
    "#writer.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning size: 10 degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n",
      "[-90 -80 -70 -60 -50 -40 -30 -20 -10   0  10  20  30  40  50  60  70  80\n",
      "  90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# remove the sampling bias\n",
    "result_original = []\n",
    "result_SamplingBiasRemoved = []\n",
    "result_flipped = []\n",
    "result_doubled = []\n",
    "\n",
    "for i in np.arange(0,24,1):\n",
    "    \n",
    "    result = []\n",
    "    result_0 = []\n",
    "    result_1 = []\n",
    "    result_2 = []\n",
    "    result_3 = []\n",
    "    \n",
    "    index = np.where(np.array(pAge) == np.mean(age_range_list[i]))\n",
    "    #print (np.mean(age_range_list[i]),np.array(pAge)[index])\n",
    "    \n",
    "    xedges = np.arange(-180, 181, 10) #180, longtitude\n",
    "    yedges = np.arange(-90, 91, 10) #90, latitude, specify the bin size\n",
    "    print (yedges)\n",
    "    data_hist = np.histogram2d(np.array(pX)[index],np.array(pY)[index], bins=(xedges, yedges))\n",
    "    result_0 = np.nansum(data_hist[0], axis=0)\n",
    "    result_original.append(result_0)\n",
    "    #print (type(result_original))\n",
    "    \n",
    "    # save the original data\n",
    "    #df = pd.DataFrame(data_hist[0].T)\n",
    "    #writer = pd.ExcelWriter('OriginalData_Glacial_%sMa.xlsx' % np.mean(age_range_list[i]), engine='xlsxwriter') # Evaporite\n",
    "    #df.to_excel(writer, sheet_name='Sheet1')\n",
    "    #writer.save()\n",
    "    \n",
    "    # remove the sampling bias\n",
    "    result_1 = np.nansum(data_hist[0]/data_hist[0], axis=0)\n",
    "    #print (result_1)\n",
    "    result_SamplingBiasRemoved.append(result_1)\n",
    "    \n",
    "    #plt.pcolor(xedges,yedges,data_hist[0].T) #T means reverse the x, y axis\n",
    "    \n",
    "    # flip the data\n",
    "    result_2 = np.flipud(result_1[:9])+result_1[9:]\n",
    "    result_flipped.append(result_2) # add data on south hemisphere to north hemishpere\n",
    "    #print (result_flipped)\n",
    "    \n",
    "    # double the data\n",
    "    result_3 = list(np.flipud(result_2)) + list(result_2) \n",
    "    result_doubled.append(np.array(result_3)) # add data on south hemisphere to north hemishpere\n",
    "    #print (result_doubled)\n",
    "\n",
    "# save data for all time steps into a table\n",
    "df = pd.DataFrame(result_original)\n",
    "writer = pd.ExcelWriter('Output/ProcessingData_2/Coals_Matthews2016_Origianl_410-0Ma_BinningSize10.xlsx' % np.mean(age_range_list[i]), engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()\n",
    "\n",
    "# save sampling bias-corrected data for all time steps into a table\n",
    "df = pd.DataFrame(result_SamplingBiasRemoved)\n",
    "writer = pd.ExcelWriter('Output/ProcessingData_2/Coals_Matthews2016_SamplingBiasCorrected_410-0Ma_BinningSize10.xlsx' % np.mean(age_range_list[i]), engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()\n",
    "\n",
    "# save flipped data for all time steps into a table\n",
    "#df = pd.DataFrame(result_flipped)\n",
    "#writer = pd.ExcelWriter('Glacial_Flipped_410-0Ma.xlsx' % np.mean(age_range_list[i]), engine='xlsxwriter')\n",
    "#df.to_excel(writer, sheet_name='Sheet1')\n",
    "#writer.save()\n",
    "\n",
    "# save flipped data for all time steps into a table\n",
    "#df = pd.DataFrame(result_doubled)\n",
    "#writer = pd.ExcelWriter('Glacial_Doubled_410-0Ma.xlsx' % np.mean(age_range_list[i]), engine='xlsxwriter')\n",
    "#df.to_excel(writer, sheet_name='Sheet1')\n",
    "#writer.save()\n",
    "\n",
    "#result_1 = []\n",
    "#result_1 = np.sum(result,axis=0) # sum up data in Y-axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning size: 2 degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# remove the sampling bias\n",
    "result_original = []\n",
    "result_SamplingBiasRemoved = []\n",
    "result_flipped = []\n",
    "result_doubled = []\n",
    "\n",
    "for i in np.arange(0,24,1):\n",
    "    \n",
    "    result = []\n",
    "    result_0 = []\n",
    "    result_1 = []\n",
    "    result_2 = []\n",
    "    result_3 = []\n",
    "    \n",
    "    index = np.where(np.array(pAge) == np.mean(age_range_list[i]))\n",
    "    #print np.mean(age_range_list[i]),np.array(pAge)[index]\n",
    "    \n",
    "    xedges = np.arange(-180, 181, 2) #180, longtitude\n",
    "    yedges = np.arange(-90, 91, 2) #90, latitude, specify the bin size\n",
    "    data_hist = np.histogram2d(np.array(pX)[index],np.array(pY)[index], bins=(xedges, yedges))\n",
    "    result_0 = np.nansum(data_hist[0], axis=0)\n",
    "    result_original.append(result_0)\n",
    "    #print type(result_original)\n",
    "    \n",
    "    # save the original data\n",
    "    #df = pd.DataFrame(data_hist[0].T)\n",
    "    #writer = pd.ExcelWriter('OriginalData_Glacial_%sMa.xlsx' % np.mean(age_range_list[i]), engine='xlsxwriter') # Evaporite\n",
    "    #df.to_excel(writer, sheet_name='Sheet1')\n",
    "    #writer.save()\n",
    "    \n",
    "    # remove the sampling bias\n",
    "    result_1 = np.nansum(data_hist[0]/data_hist[0], axis=0)\n",
    "    #print (result_1)\n",
    "    result_SamplingBiasRemoved.append(result_1)\n",
    "    \n",
    "    #plt.pcolor(xedges,yedges,data_hist[0].T) #T means reverse the x, y axis\n",
    "    \n",
    "    # flip the data\n",
    "    result_2 = np.flipud(result_1[:45])+result_1[45:]\n",
    "    result_flipped.append(result_2) # add data on south hemisphere to north hemishpere\n",
    "    #print (result_flipped)\n",
    "    \n",
    "    # double the data\n",
    "    result_3 = list(np.flipud(result_2)) + list(result_2) \n",
    "    result_doubled.append(np.array(result_3)) # add data on south hemisphere to north hemishpere\n",
    "    #print (result_doubled)\n",
    "\n",
    "# save data for all time steps into a table\n",
    "df = pd.DataFrame(result_original)\n",
    "writer = pd.ExcelWriter('Output/ProcessingData_2/Coals_Matthews2016_Origianl_410-0Ma_BinningSize2.xlsx' % np.mean(age_range_list[i]), engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "#writer.save()\n",
    "\n",
    "# save sampling bias-corrected data for all time steps into a table\n",
    "df = pd.DataFrame(result_SamplingBiasRemoved)\n",
    "writer = pd.ExcelWriter('Output/ProcessingData_2/Coals_Matthews2016_SamplingBiasCorrected_410-0Ma_BinningSize2.xlsx' % np.mean(age_range_list[i]), engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()\n",
    "\n",
    "# save flipped data for all time steps into a table\n",
    "#df = pd.DataFrame(result_flipped)\n",
    "#writer = pd.ExcelWriter('Glacial_Flipped_410-0Ma.xlsx' % np.mean(age_range_list[i]), engine='xlsxwriter')\n",
    "#df.to_excel(writer, sheet_name='Sheet1')\n",
    "#writer.save()\n",
    "\n",
    "# save flipped data for all time steps into a table\n",
    "#df = pd.DataFrame(result_doubled)\n",
    "#writer = pd.ExcelWriter('Glacial_Doubled_410-0Ma.xlsx' % np.mean(age_range_list[i]), engine='xlsxwriter')\n",
    "#df.to_excel(writer, sheet_name='Sheet1')\n",
    "#writer.save()\n",
    "\n",
    "#result_1 = []\n",
    "#result_1 = np.sum(result,axis=0) # sum up data in Y-axis\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
